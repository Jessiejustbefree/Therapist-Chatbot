{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11126046,"sourceType":"datasetVersion","datasetId":6938634},{"sourceId":11165365,"sourceType":"datasetVersion","datasetId":6967546}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U langchain_huggingface faiss-cpu faiss-gpu beautifulsoup4 requests transformers peft accelerate bitsandbytes langchain_community langgraph pymupdf langchain_openai PyPDF2 trl torch torchvision\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T15:22:42.146142Z","iopub.execute_input":"2025-04-04T15:22:42.146549Z","iopub.status.idle":"2025-04-04T15:25:50.005470Z","shell.execute_reply.started":"2025-04-04T15:22:42.146516Z","shell.execute_reply":"2025-04-04T15:25:50.004598Z"}},"outputs":[{"name":"stdout","text":"Collecting langchain_huggingface\n  Downloading langchain_huggingface-0.1.2-py3-none-any.whl.metadata (1.3 kB)\nCollecting faiss-cpu\n  Downloading faiss_cpu-1.10.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\nCollecting faiss-gpu\n  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\nCollecting beautifulsoup4\n  Downloading beautifulsoup4-4.13.3-py3-none-any.whl.metadata (3.8 kB)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nCollecting transformers\n  Downloading transformers-4.50.3-py3-none-any.whl.metadata (39 kB)\nRequirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.14.0)\nCollecting peft\n  Downloading peft-0.15.1-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.2.1)\nCollecting accelerate\n  Downloading accelerate-1.6.0-py3-none-any.whl.metadata (19 kB)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.45.4-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\nCollecting langchain_community\n  Downloading langchain_community-0.3.21-py3-none-any.whl.metadata (2.4 kB)\nCollecting langgraph\n  Downloading langgraph-0.3.25-py3-none-any.whl.metadata (7.7 kB)\nCollecting pymupdf\n  Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\nCollecting langchain_openai\n  Downloading langchain_openai-0.3.12-py3-none-any.whl.metadata (2.3 kB)\nCollecting PyPDF2\n  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\nCollecting trl\n  Downloading trl-0.16.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nCollecting torch\n  Downloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\nCollecting torchvision\n  Downloading torchvision-0.21.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.1 kB)\nRequirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langchain_huggingface) (0.29.0)\nRequirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain_huggingface) (0.3.25)\nRequirement already satisfied: sentence-transformers>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from langchain_huggingface) (3.3.1)\nRequirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from langchain_huggingface) (0.21.0)\nRequirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.2)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\nRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2025.1.31)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\nCollecting langchain-core<0.4.0,>=0.3.15 (from langchain_huggingface)\n  Downloading langchain_core-0.3.51-py3-none-any.whl.metadata (5.9 kB)\nCollecting langchain<1.0.0,>=0.3.23 (from langchain_community)\n  Downloading langchain-0.3.23-py3-none-any.whl.metadata (7.8 kB)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.36)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.11.12)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (9.0.0)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\nCollecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\nRequirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.3)\nCollecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\nCollecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph)\n  Downloading langgraph_checkpoint-2.0.24-py3-none-any.whl.metadata (4.6 kB)\nCollecting langgraph-prebuilt<0.2,>=0.1.1 (from langgraph)\n  Downloading langgraph_prebuilt-0.1.8-py3-none-any.whl.metadata (5.0 kB)\nCollecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n  Downloading langgraph_sdk-0.1.61-py3-none-any.whl.metadata (1.8 kB)\nRequirement already satisfied: xxhash<4.0.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from langgraph) (3.5.0)\nCollecting openai<2.0.0,>=1.68.2 (from langchain_openai)\n  Downloading openai-1.70.0-py3-none-any.whl.metadata (25 kB)\nRequirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.9.0)\nRequirement already satisfied: datasets>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from trl) (3.3.1)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from trl) (13.9.4)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparselt-cu12==0.6.2 (from torch)\n  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\nCollecting nvidia-nccl-cu12==2.21.5 (from torch)\n  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting triton==3.2.0 (from torch)\n  Downloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=3.0.0->trl) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=3.0.0->trl) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=3.0.0->trl) (2.2.3)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets>=3.0.0->trl) (0.70.16)\nCollecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain<1.0.0,>=0.3.23->langchain_community)\n  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<1.0.0,>=0.3.23->langchain_community) (2.11.0a2)\nCollecting async-timeout<6.0,>=4.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.33)\nCollecting ormsgpack<2.0.0,>=1.8.0 (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph)\n  Downloading ormsgpack-1.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.10/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\nRequirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.10/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.12)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2.4.1)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (3.7.1)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.9.0)\nRequirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.8.2)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.3.1)\nCollecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.13.1)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl) (2.19.1)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain_openai) (1.2.2)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (3.0.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain_community) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain_community) (2.29.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=3.0.0->trl) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (3.5.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl) (1.17.0)\nDownloading langchain_huggingface-0.1.2-py3-none-any.whl (21 kB)\nDownloading faiss_cpu-1.10.0-cp310-cp310-manylinux_2_28_x86_64.whl (30.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading beautifulsoup4-4.13.3-py3-none-any.whl (186 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m186.0/186.0 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading transformers-4.50.3-py3-none-any.whl (10.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m114.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading peft-0.15.1-py3-none-any.whl (411 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.0/411.0 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading accelerate-1.6.0-py3-none-any.whl (354 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.7/354.7 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.45.4-py3-none-manylinux_2_24_x86_64.whl (76.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading langchain_community-0.3.21-py3-none-any.whl (2.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading langgraph-0.3.25-py3-none-any.whl (142 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.4/142.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading langchain_openai-0.3.12-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading trl-0.16.0-py3-none-any.whl (335 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m335.7/335.7 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl (766.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m100.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.1/253.1 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchvision-0.21.0-cp310-cp310-manylinux1_x86_64.whl (7.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m107.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\nDownloading langchain-0.3.23-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_core-0.3.51-py3-none-any.whl (423 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.3/423.3 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langgraph_checkpoint-2.0.24-py3-none-any.whl (42 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langgraph_prebuilt-0.1.8-py3-none-any.whl (25 kB)\nDownloading langgraph_sdk-0.1.61-py3-none-any.whl (47 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading openai-1.70.0-py3-none-any.whl (599 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m599.1/599.1 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\nDownloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\nDownloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\nDownloading ormsgpack-1.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (223 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\nInstalling collected packages: triton, nvidia-cusparselt-cu12, faiss-gpu, python-dotenv, PyPDF2, pymupdf, ormsgpack, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, httpx-sse, beautifulsoup4, async-timeout, nvidia-cusparse-cu12, nvidia-cudnn-cu12, pydantic-settings, openai, nvidia-cusolver-cu12, langgraph-sdk, torch, langchain-core, langgraph-checkpoint, langchain-text-splitters, langchain_openai, langgraph-prebuilt, langchain, langgraph, transformers, accelerate, trl, torchvision, peft, langchain_huggingface, langchain_community, faiss-cpu, bitsandbytes\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.23.4\n    Uninstalling nvidia-nccl-cu12-2.23.4:\n      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.7.77\n    Uninstalling nvidia-curand-cu12-10.3.7.77:\n      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n  Attempting uninstall: beautifulsoup4\n    Found existing installation: beautifulsoup4 4.12.3\n    Uninstalling beautifulsoup4-4.12.3:\n      Successfully uninstalled beautifulsoup4-4.12.3\n  Attempting uninstall: async-timeout\n    Found existing installation: async-timeout 5.0.1\n    Uninstalling async-timeout-5.0.1:\n      Successfully uninstalled async-timeout-5.0.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.6.0.74\n    Uninstalling nvidia-cudnn-cu12-9.6.0.74:\n      Successfully uninstalled nvidia-cudnn-cu12-9.6.0.74\n  Attempting uninstall: openai\n    Found existing installation: openai 1.57.4\n    Uninstalling openai-1.57.4:\n      Successfully uninstalled openai-1.57.4\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n  Attempting uninstall: torch\n    Found existing installation: torch 2.5.1+cu121\n    Uninstalling torch-2.5.1+cu121:\n      Successfully uninstalled torch-2.5.1+cu121\n  Attempting uninstall: langchain-core\n    Found existing installation: langchain-core 0.3.25\n    Uninstalling langchain-core-0.3.25:\n      Successfully uninstalled langchain-core-0.3.25\n  Attempting uninstall: langchain-text-splitters\n    Found existing installation: langchain-text-splitters 0.3.3\n    Uninstalling langchain-text-splitters-0.3.3:\n      Successfully uninstalled langchain-text-splitters-0.3.3\n  Attempting uninstall: langchain\n    Found existing installation: langchain 0.3.12\n    Uninstalling langchain-0.3.12:\n      Successfully uninstalled langchain-0.3.12\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.47.0\n    Uninstalling transformers-4.47.0:\n      Successfully uninstalled transformers-4.47.0\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 1.2.1\n    Uninstalling accelerate-1.2.1:\n      Successfully uninstalled accelerate-1.2.1\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.20.1+cu121\n    Uninstalling torchvision-0.20.1+cu121:\n      Successfully uninstalled torchvision-0.20.1+cu121\n  Attempting uninstall: peft\n    Found existing installation: peft 0.14.0\n    Uninstalling peft-0.14.0:\n      Successfully uninstalled peft-0.14.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0 which is incompatible.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\npylibcugraph-cu12 24.10.0 requires pylibraft-cu12==24.10.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.10.0 requires rmm-cu12==24.10.*, but you have rmm-cu12 25.2.0 which is incompatible.\ntorchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.6.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed PyPDF2-3.0.1 accelerate-1.6.0 async-timeout-4.0.3 beautifulsoup4-4.13.3 bitsandbytes-0.45.4 faiss-cpu-1.10.0 faiss-gpu-1.7.2 httpx-sse-0.4.0 langchain-0.3.23 langchain-core-0.3.51 langchain-text-splitters-0.3.8 langchain_community-0.3.21 langchain_huggingface-0.1.2 langchain_openai-0.3.12 langgraph-0.3.25 langgraph-checkpoint-2.0.24 langgraph-prebuilt-0.1.8 langgraph-sdk-0.1.61 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 openai-1.70.0 ormsgpack-1.9.1 peft-0.15.1 pydantic-settings-2.8.1 pymupdf-1.25.5 python-dotenv-1.1.0 torch-2.6.0 torchvision-0.21.0 transformers-4.50.3 triton-3.2.0 trl-0.16.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from langchain.agents import tool\n\nfrom langchain_community.document_loaders import WebBaseLoader\n\nfrom langchain_community.vectorstores import FAISS\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\nfrom langchain.agents import tool\n\nimport os\nimport nest_asyncio\nfrom PyPDF2 import PdfReader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.vectorstores import FAISS\nfrom langchain_huggingface import HuggingFaceEmbeddings  # Updated import\nfrom langchain.schema import Document\n\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\nfrom langchain.chains import ConversationChain\nfrom langchain.memory import ConversationBufferMemory\nfrom langchain.prompts import PromptTemplate\nfrom langchain.llms import HuggingFacePipeline\nimport torchvision\ntorchvision.disable_beta_transforms_warning()\n\nimport bs4\nfrom langchain_community.document_loaders import WebBaseLoader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T15:25:50.006781Z","iopub.execute_input":"2025-04-04T15:25:50.007101Z","iopub.status.idle":"2025-04-04T15:26:11.387755Z","shell.execute_reply.started":"2025-04-04T15:25:50.007066Z","shell.execute_reply":"2025-04-04T15:26:11.387083Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"def load_pdfs_from_folder(folder_path):\n    pdf_documents = []\n    for filename in os.listdir(folder_path):\n        if filename.endswith(\".pdf\"):\n            file_path = os.path.join(folder_path, filename)\n            with open(file_path, 'rb') as f:\n                reader = PdfReader(f)\n                text = \"\\n\".join([page.extract_text() for page in reader.pages if page.extract_text()])\n                pdf_documents.append(Document(page_content=text))  # Convert to LangChain Document\n    return pdf_documents\n\n# Improved text splitting function\ndef split_documents(documents, chunk_size=1000, chunk_overlap=200):\n    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n    split_documents = text_splitter.split_documents(documents)\n    return split_documents\n\n# Function to load and process documents for RAG (only PDFs now)\ndef load_and_process_documents(pdf_folder):\n    # Load PDFs from folder\n    pdf_documents = load_pdfs_from_folder(pdf_folder)\n\n    # Split documents into manageable chunks\n    split_documents_list = split_documents(pdf_documents)\n\n    return split_documents_list\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T15:26:11.389166Z","iopub.execute_input":"2025-04-04T15:26:11.389742Z","iopub.status.idle":"2025-04-04T15:26:11.395199Z","shell.execute_reply.started":"2025-04-04T15:26:11.389719Z","shell.execute_reply":"2025-04-04T15:26:11.394420Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# # Load documents (only PDFs)\n# folder_path = \"/kaggle/input/therapist-docs/RAG docs\"\n# documents = load_and_process_documents(folder_path)\n\n# Define embedding model (using the updated HuggingFaceEmbeddings)\nembeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-mpnet-base-v2')\n\n# # Create FAISS vector store\n# vector_db = FAISS.from_documents(documents, embeddings)\n\n# vector_db.save_local(\"/kaggle/working/FAISS\")\n\n# # Define retriever with improved parameters for better retrieval\n# retriever = vector_db.as_retriever(search_type=\"similarity\", search_kwargs={'k': 4})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T15:26:11.396607Z","iopub.execute_input":"2025-04-04T15:26:11.396917Z","iopub.status.idle":"2025-04-04T15:26:20.165417Z","shell.execute_reply.started":"2025-04-04T15:26:11.396886Z","shell.execute_reply":"2025-04-04T15:26:20.164485Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2fe736f2f484568a2e201770bd609b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a0e040295c24b2bae73530ac0693506"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f026ec1809b4525adbc94c34ef182d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89d7f399c37c44ecb7222da51fe0ed48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34d23d8e7ae14e97af5a6c4ec32591da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8ae96bbe86b48a2acb2b849e9a53948"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42658d0077d448d6aa7f0545f0057c99"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35afca56bfde4351a259543ecc87c654"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75cd0ac660f745d5b89a86ab278be483"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdebbf64763841b2869612588b23191b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab2013974bc24258a53e5f3df44edb99"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# relevant_webpages = [\n#     \"https://beckinstitute.org/beck-institute-role-play-transcript-abe-therapy-session-2\",\n#     \"https://beckinstitute.org/wp-content/uploads/2021/06/BB3-Session-2-Annotated-Transcript.pdf\",\n#     \"https://www.cci.health.wa.gov.au/Training/Demonstration-Videos\",\n#     \"https://www.psychotherapy.net/data/fe/file/Somme_Couns_transcript.pdf\",\n#     \"https://kmb.camh.ca/ggtu/Documents/cbt-clinical-simulation-transcript.pdf\",\n#     \"https://www.mirecc.va.gov/visn16/docs/therapists_guide_to_brief_cbtmanual.pdf\",\n#     \"https://www.cci.health.wa.gov.au/Resources/Looking-After-Yourself\"\n# ]\n\n# bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))\n\n# for webpage in relevant_webpages:\n#     try:\n#         # Load webpage content\n#         response = requests.get(webpage, verify=False)  # Disable SSL verification (use cautiously)\n#         print(response.status_code)\n#         loader = WebBaseLoader(web_paths=[webpage], bs_kwargs={\"parse_only\": bs4_strainer})\n#         docs = loader.load()\n\n#         # Split into chunks\n#         text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n#         split_documents = text_splitter.split_documents(docs)\n\n#         # Add to FAISS index\n#         vector_db.add_documents(split_documents)\n\n#     except Exception as e:\n#         print(f\"Error loading {webpage}: {e}\")\n\n# vector_db.save_local(\"/kaggle/working/FAISS\")\n# retriever = vector_db.as_retriever(search_type=\"similarity\", search_kwargs={'k': 4})\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T15:26:20.166427Z","iopub.execute_input":"2025-04-04T15:26:20.166776Z","iopub.status.idle":"2025-04-04T15:26:20.170296Z","shell.execute_reply.started":"2025-04-04T15:26:20.166743Z","shell.execute_reply":"2025-04-04T15:26:20.169501Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Load FAISS index\n### RAG functions\nembeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-mpnet-base-v2') #model_kwargs={\"device\": \"cpu\"}\nfaiss_index = FAISS.load_local(\"/kaggle/input/faiss-index-2\", embeddings=embeddings,allow_dangerous_deserialization = True)\n\nretriever = faiss_index.as_retriever(search_type=\"similarity\", search_kwargs={'k': 4})\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T15:26:20.171223Z","iopub.execute_input":"2025-04-04T15:26:20.171535Z","iopub.status.idle":"2025-04-04T15:26:21.370192Z","shell.execute_reply.started":"2025-04-04T15:26:20.171503Z","shell.execute_reply":"2025-04-04T15:26:21.369450Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"Tool Function\tRecommended Type\tWhy?\nRAG for retrieving therapy-related responses-Structured Tool: Outputs formatted data (retrieved documents)\nMemory tracking (checking distress, session booking in JSON)-Subclass-Based Tool: Needs custom logic for storing structured session data\nSuicidal Detection & Notification-Subclass-Based Tool: Requires specialized logic to trigger alerts\nGuardrails (Filtering harmful responses)-Normal Tool: Simple validation of responses\nCalming Music Recommendation-Normal Tool: Simple retrieval of URLs","metadata":{}},{"cell_type":"code","source":"import json\nfrom langchain.tools import BaseTool\nfrom typing import Dict\n\n# Store per-session distress data\ndistress_memory_store: Dict[str, Dict] = {}\n\nclass MemoryTrackingTool(BaseTool):\n    name: str = \"distress_memory_tracker\"  # ✅ Must be annotated!\n    description: str = \"Detects distress in user input. Format: 'session_id::message'.\"\n\n    def _run(self, input: str) -> str:\n        try:\n            session_id, user_input = input.split(\"::\", 1)\n        except ValueError:\n            return \"Invalid format. Use 'session_id::message'\"\n\n        # Track memory per session\n        if session_id not in distress_memory_store:\n            distress_memory_store[session_id] = {\"distress_count\": 0, \"session_booked\": False}\n\n        session_data = distress_memory_store[session_id]\n\n        distress_keywords = [\"hopeless\", \"helpless\", \"overwhelmed\", \"exhausted\"]\n        session_keywords = [\"book session\", \"schedule appointment\"]\n\n        if any(word in user_input.lower() for word in distress_keywords):\n            session_data[\"distress_count\"] += 1\n            if session_data[\"distress_count\"] >= 3 and not session_data[\"session_booked\"]:\n                return \"You've mentioned distress multiple times. Would you like to book a session with a counselor?\"\n\n        if any(word in user_input.lower() for word in session_keywords):\n            session_data[\"session_booked\"] = True\n            with open(\"session_bookings.json\", \"a\") as f:\n                json.dump({session_id: \"booked\"}, f)\n                f.write(\"\\n\")\n            return \"Your session has been booked.\"\n\n        return \"Monitoring your responses. Let me know if you'd like to talk more or book a session.\"\n\nmemory_tool = MemoryTrackingTool()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T15:26:21.371042Z","iopub.execute_input":"2025-04-04T15:26:21.371339Z","iopub.status.idle":"2025-04-04T15:26:21.381988Z","shell.execute_reply.started":"2025-04-04T15:26:21.371314Z","shell.execute_reply":"2025-04-04T15:26:21.381200Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class SuicidalDetectionTool(BaseTool):\n    name: str = \"suicidal_detection\"\n    description: str = \"Detects suicidal thoughts and triggers notifications.\"\n\n    def _run(self, user_input: str):\n        \"\"\"Detects suicidal intent and triggers intervention if needed.\"\"\"\n        suicidal_keywords = [\"I want to die\", \"end my life\", \"can't go on\", \"no point in living\"]\n\n        if any(phrase in user_input.lower() for phrase in suicidal_keywords):\n            return \"\"\"I'm really sorry to hear that you're feeling this way. You are not alone. \n    Please consider reaching out to a trusted friend, family member, or professional.\n    \n    If you are in immediate danger, please contact a crisis helpline:\n    - Singapore: Samaritans of Singapore (SOS) - 1767\n    - USA: National Suicide Prevention Lifeline - 988\n    - UK: Samaritans - 116 123\n    \"\"\"\n\n        return \"No suicidal intent detected.\"\n\nsuicidal_tool = SuicidalDetectionTool()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T15:26:21.384213Z","iopub.execute_input":"2025-04-04T15:26:21.384415Z","iopub.status.idle":"2025-04-04T15:26:21.406012Z","shell.execute_reply.started":"2025-04-04T15:26:21.384398Z","shell.execute_reply":"2025-04-04T15:26:21.405309Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"from langchain.tools import Tool\n\ndef recommend_calming_music():\n    \"\"\"Returns a calming music playlist when anxiety is detected.\"\"\"\n    return [\n        \"https://www.youtube.com/watch?v=2OEL4P1Rz04\",  # Deep Sleep Music\n        \"https://www.youtube.com/watch?v=1ZYbU82GVz4\",  # Relaxing Piano\n        \"https://www.youtube.com/watch?v=3O31iF5c6ac\"   # Meditation Music\n    ]\n\nmusic_tool = Tool.from_function(\n    func=recommend_calming_music,\n    name=\"calming_music\",\n    description=\"Recommends relaxing music links when anxiety is detected.\"\n)\n\ndef filter_harmful_response(response: str):\n    \"\"\"Ensure generated response does not contain harmful content.\"\"\"\n    blocked_phrases = [\"self-harm\", \"suicide\", \"violence\"]\n\n    if any(word in response.lower() for word in blocked_phrases):\n        return \"I'm sorry, but I can't discuss this topic. If you're struggling, please seek help from a licensed professional or helpline.\"\n\n    return response\n\nguardrail_tool = Tool.from_function(\n    func=filter_harmful_response,\n    name=\"guardrail_filter\",\n    description=\"Filters AI-generated responses to prevent harmful content.\"\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T15:26:21.407424Z","iopub.execute_input":"2025-04-04T15:26:21.407688Z","iopub.status.idle":"2025-04-04T15:26:21.426517Z","shell.execute_reply.started":"2025-04-04T15:26:21.407665Z","shell.execute_reply":"2025-04-04T15:26:21.425833Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from huggingface_hub import login\n# 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\nlogin()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T15:28:18.000449Z","iopub.execute_input":"2025-04-04T15:28:18.000807Z","iopub.status.idle":"2025-04-04T15:28:18.017799Z","shell.execute_reply.started":"2025-04-04T15:28:18.000781Z","shell.execute_reply":"2025-04-04T15:28:18.016831Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e88fb3baab1242ad840b70d7b49bdbf8"}},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T15:28:33.381926Z","iopub.execute_input":"2025-04-04T15:28:33.382222Z","iopub.status.idle":"2025-04-04T15:28:33.385961Z","shell.execute_reply.started":"2025-04-04T15:28:33.382201Z","shell.execute_reply":"2025-04-04T15:28:33.385028Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"import os\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T15:28:33.801200Z","iopub.execute_input":"2025-04-04T15:28:33.801477Z","iopub.status.idle":"2025-04-04T15:28:33.805322Z","shell.execute_reply.started":"2025-04-04T15:28:33.801456Z","shell.execute_reply":"2025-04-04T15:28:33.804401Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T15:28:34.261882Z","iopub.execute_input":"2025-04-04T15:28:34.262193Z","iopub.status.idle":"2025-04-04T15:28:34.478333Z","shell.execute_reply.started":"2025-04-04T15:28:34.262169Z","shell.execute_reply":"2025-04-04T15:28:34.477458Z"}},"outputs":[{"name":"stdout","text":"Fri Apr  4 15:28:34 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n| N/A   39C    P0             33W /  250W |     995MiB /  16384MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"!nvidia-smi --query-compute-apps=pid,used_memory --format=csv","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T15:28:35.389480Z","iopub.execute_input":"2025-04-04T15:28:35.389861Z","iopub.status.idle":"2025-04-04T15:28:35.578577Z","shell.execute_reply.started":"2025-04-04T15:28:35.389829Z","shell.execute_reply":"2025-04-04T15:28:35.577494Z"}},"outputs":[{"name":"stdout","text":"pid, used_gpu_memory [MiB]\n3105, 992 MiB\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, pipeline,BitsAndBytesConfig\n# from langchain.llms import HuggingFacePipeline\nfrom langchain_huggingface import ChatHuggingFace, HuggingFacePipeline \n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Load Model 1 on CPU\nmodel1_name = \"gpt2\"\nmodel_memory = AutoModelForCausalLM.from_pretrained(model1_name,torch_dtype=torch.float16,).to(\"cpu\")\ntokenizer_memory = AutoTokenizer.from_pretrained(model1_name)\nrephrase_generator = pipeline(\"text-generation\", model=model_memory, tokenizer=tokenizer_memory)\nllm_rephrase = HuggingFacePipeline(pipeline=rephrase_generator)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T15:28:35.948596Z","iopub.execute_input":"2025-04-04T15:28:35.948933Z","iopub.status.idle":"2025-04-04T15:28:36.650736Z","shell.execute_reply.started":"2025-04-04T15:28:35.948909Z","shell.execute_reply":"2025-04-04T15:28:36.650036Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# Load Model 2 on GPU\nfrom peft import PeftModel\n\nmodel2_name = \"Jesslyn26/improved_mistral_7b_combined_3\"\nquantization_config = BitsAndBytesConfig(\n    load_in_4bit=True,  # Enables QLoRA (4-bit)\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16,  # Use FP16 for computations\n    bnb_4bit_use_double_quant=True,  # Double quantization for lower memory\n)\nmistral_tokenizer = AutoTokenizer.from_pretrained(model2_name)\ndevice = torch.device(\"cuda:1\" if torch.cuda.device_count() > 1 else \"cuda:0\")\nmistral = AutoModelForCausalLM.from_pretrained(model2_name,quantization_config=quantization_config,\n    device_map=\"auto\",\n    use_cache=False)\nmistral_generator = pipeline(\"text-generation\", model=mistral, tokenizer=mistral_tokenizer, max_new_tokens=500) #llm_chain\nllm_mistral = HuggingFacePipeline(pipeline=mistral_generator)\nchat_model = ChatHuggingFace(llm=llm_mistral)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T15:28:39.945710Z","iopub.execute_input":"2025-04-04T15:28:39.946166Z","iopub.status.idle":"2025-04-04T15:30:05.032752Z","shell.execute_reply.started":"2025-04-04T15:28:39.946136Z","shell.execute_reply":"2025-04-04T15:30:05.031806Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/601 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17b18a9b280644278a86571894ca38d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"427357d0176746bebbe5f5a278e42bb1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"745414ed7b6642dc9787eac319d6ad4e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83298361c2334252a2773f962828644d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/4.55G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41ea504a7ce14782845bd0da71e270f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb0fe692c26c4e72bf0e8dd69286cedc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e709ba929ba480ea33c1041a60f7f2f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3e421803b6744fc84187e848e69cf6f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/109M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c028f588638049c1be51269b1446c07e"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/141k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"490d100da17d450d96296149fa446aed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/587k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16d90aa761774d06b69c05b380b8eb5d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec89e6de06914faea2a4fc98e42671e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d115c5fed26a49f58e3496dc5b0eb77e"}},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"chat_model.invoke(\"test\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T15:30:05.033846Z","iopub.execute_input":"2025-04-04T15:30:05.034147Z","iopub.status.idle":"2025-04-04T15:30:18.232816Z","shell.execute_reply.started":"2025-04-04T15:30:05.034125Z","shell.execute_reply":"2025-04-04T15:30:18.231898Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"AIMessage(content=\"<s>[INST] test[/INST] It seems like you'd like to test the functionality of this text-based AI. I'm here to help! How can I assist you today? Let's chat about a topic you're interested in, or ask me a question. I'll do my best to provide a helpful and friendly response.\\n\\nFor example, you could ask me about:\\n- Facts about a specific subject\\n- Explanations of complex concepts\\n- Recommendations for books, movies, or TV shows\\n- Advice on personal or professional issues\\n- Instructions for completing a task\\n- Or just about anything else you'd like to discuss!\\n\\nI'm looking forward to our conversation. Let's get started!\", additional_kwargs={}, response_metadata={}, id='run-f847060d-b58f-4608-a8b3-5806535d3f55-0')"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T15:30:18.234489Z","iopub.execute_input":"2025-04-04T15:30:18.234835Z","iopub.status.idle":"2025-04-04T15:30:18.504709Z","shell.execute_reply.started":"2025-04-04T15:30:18.234802Z","shell.execute_reply":"2025-04-04T15:30:18.503651Z"}},"outputs":[{"name":"stdout","text":"Fri Apr  4 15:30:18 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n| N/A   45C    P0             40W /  250W |    5463MiB /  16384MiB |     51%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"!ps -fp 1729","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T15:30:18.506456Z","iopub.execute_input":"2025-04-04T15:30:18.506944Z","iopub.status.idle":"2025-04-04T15:30:18.743113Z","shell.execute_reply.started":"2025-04-04T15:30:18.506919Z","shell.execute_reply":"2025-04-04T15:30:18.742039Z"}},"outputs":[{"name":"stdout","text":"UID          PID    PPID  C STIME TTY          TIME CMD\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"from langchain.tools import StructuredTool\nfrom pydantic import BaseModel\nfrom typing import TypedDict\nfrom typing import List, ClassVar\nimport gc \nfrom pydantic import Field, root_validator\n\n\n\n# Define prompt for generating standalone question\n_standalone_template = \"\"\"\n[INST]\nYou are an empathetic therapy assistant. Given a conversation history and a follow-up user statement,\nyour task is to rewrite the statement as a **standalone query** to retrieve **relevant therapeutic advice** to give to user.\nChat History:\n{chat_history}\n\nFollow Up Input: {question}\n\nStandalone Question:\n[/INST]\n\"\"\"\n\nSTANDALONE_QUESTION_PROMPT = PromptTemplate.from_template(_standalone_template)\n\nclass RephraseInputDict(BaseModel):\n    question: str\n    chat_history: str\n\n# Function to rephrase the question (ensure text format for model input)\ndef rephrase_question(question: str, chat_history: str):\n    with torch.no_grad():  \n        prompt = STANDALONE_QUESTION_PROMPT.format(question=question, chat_history=chat_history)\n        inputs = tokenizer_memory(prompt, return_tensors=\"pt\").to(\"cuda\")\n        output = model_memory.generate(**inputs, max_new_tokens=100, temperature=0.0, repetition_penalty=1.1)\n    \n    del inputs\n    gc.collect()\n    torch.cuda.empty_cache() \n\n    print(tokenizer_memory.decode(output[0], skip_special_tokens=True))\n    return tokenizer_memory.decode(output[0], skip_special_tokens=True)\n\nrephrase_tool = StructuredTool.from_function(\n    func=rephrase_question,\n    name=\"query_rephraser\",\n    description=\"Rephrases user input into a standalone query for FAISS retrieval.\",\n    args_schema=RephraseInputDict)\n\n\n\n# def retrieve_documents(query: str,faiss_index, top_k=4):\n#     \"\"\"Retrieve therapy-related documents based on user input.\"\"\"\n#     query = str(query)\n#     documents = faiss_index.similarity_search(query, k=top_k)\n#     return [str(doc.page_content) for doc in documents]\n\n# retriever_tool = StructuredTool.from_function(\n#     func=retrieve_documents,\n#     name=\"therapy_rag_retrieval\",\n#     description=\"Retrieves relevant therapy documents from RAG storage.\"\n# )\n\n\n# Define function that accepts the schema\ndef retrieve_documents(input_data):\n    \"\"\"Retrieve therapy-related documents based on user input.\"\"\"\n    documents = faiss_index.similarity_search(input_data, k=4)\n    return [doc.page_content for doc in documents]\n\n# Define retriever tool\nretriever_tool = StructuredTool.from_function(\n    func=retrieve_documents,\n    name=\"therapy_rag_retrieval\",\n    description=\"Retrieves relevant therapy documents from FAISS storage.\",  \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T15:30:18.744341Z","iopub.execute_input":"2025-04-04T15:30:18.744666Z","iopub.status.idle":"2025-04-04T15:30:18.763752Z","shell.execute_reply.started":"2025-04-04T15:30:18.744621Z","shell.execute_reply":"2025-04-04T15:30:18.762784Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"from langchain.agents import create_tool_calling_agent\nfrom langchain_core.messages import AIMessage, HumanMessage\nfrom langchain_community.chat_message_histories import ChatMessageHistory\nfrom langchain_core.chat_history import BaseChatMessageHistory\nfrom langchain_core.runnables.history import RunnableWithMessageHistory\nfrom langchain.agents import AgentExecutor\nfrom langchain_core.messages import trim_messages\nfrom langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate\nfrom langgraph.prebuilt import create_react_agent\nfrom langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, MessagesPlaceholder\nfrom langgraph.prebuilt import create_react_agent\nfrom langgraph.graph import StateGraph, END\nfrom langchain_core.runnables.history import RunnableWithMessageHistory\nfrom langchain.agents import AgentExecutor\nfrom langchain_core.runnables import RunnableLambda\n\nfrom typing import TypedDict\n\n# Define input/output state schema\nclass AgentState(TypedDict):\n    input: str\n    output: str\n\n\ndef generate_rag_response(query,faiss_index, id, rephrase_tool, retriever_tool,llm_mistral):\n\n    safety_flag = suicidal_tool.invoke(query)\n    if \"crisis\" in safety_flag.lower():\n        return safety_flag \n    \n    memory = get_session_history(id)\n    \n    chat_history = memory.messages\n\n    chat_history_str = \"\\n\".join([str(msg) for msg in chat_history]) if chat_history else \"No previous messages.\"\n    \n    rephrased_input = rephrase_tool.invoke({\"question\": query, \"chat_history\": chat_history_str})\n    # Retrieve relevant documents from FAISS\n    print(rephrased_input)\n    retrieved_docs = retriever_tool.invoke(rephrased_input)\n    \n    context = \"\\n\\n\".join(retrieved_docs)\n\n    # Construct prompt for fine-tuned model with context and chat history\n    system_prompt_text = f\"\"\"\n    ### Instruction:\n    You are a supportive and empathetic therapy chatbot trained in evidence-based counseling techniques. \n\n    Guidelines:\n    - You **do not diagnose** mental health conditions.\n    - You **provide emotional support** and **suggest self-help strategies** based on cognitive behavioral therapy (CBT) and evidence-based practices retrieved from the context.\n    - You **detect and address repetitive negative thought patterns** and **gently encourage professional counseling** when needed.\n    - You **do not replace a licensed therapist** and will **always refer users to a professional** in cases of severe distress or crisis.\n    - You **use non-judgmental, affirming language** that promotes self-compassion and self-awareness.\n    \n    Response Style:\n    - Use **motivational interviewing techniques** (e.g., open-ended questions, reflections, affirmations).\n    - Provide **psychoeducation** where relevant.\n    - If the user expresses crisis-level distress (e.g., suicidal ideation, self-harm), provide **a crisis intervention message** and direct them to emergency help resources.\n\n    ### Context from Retrieved Documents:\n    {context}\n    \"\"\"\n\n    tools=[ memory_tool, suicidal_tool, guardrail_tool, music_tool]\n    \n    # 2. Create agent using langgraph's create_react_agent\n    agent = create_react_agent(\n        llm_mistral,           # Your LLM, e.g., HuggingFacePipeline or ChatOpenAI\n        tools=tools,               # [memory_tool, suicidal_tool, guardrail_tool, music_tool]\n        prompt=system_prompt_text\n    )\n\n\n    def wrapped_agent_node(state):\n        prompt = ChatPromptTemplate.from_messages([\n            MessagesPlaceholder(variable_name=\"history\"),\n            (\"human\", \"{question}\"),\n        ])\n        messages = prompt.invoke(state).to_messages()\n        print(messages)\n        return agent.invoke({\"messages\": messages})[\"messages\"][-1]\n  \n\n    prompt = ChatPromptTemplate.from_messages([\n        MessagesPlaceholder(variable_name=\"history\"),\n        (\"human\", \"{question}\"),\n    ])\n    \n    # Optional: Add memory tracking using RunnableWithMessageHistory\n    graph_with_memory = RunnableWithMessageHistory(\n        RunnableLambda(wrapped_agent_node),\n        get_session_history,  # your memory/session retriever function\n        input_messages_key=\"question\",\n        history_messages_key=\"history\",\n    )\n    \n    # 4. Prepare input and invoke\n    input_with_id = f\"{id}::{query}\"\n    \n    response = graph_with_memory.invoke(\n        {\"question\": input_with_id},\n        config={\"configurable\": {\"session_id\": id}}\n    )\n    \n    print(response)\n    \n    final_output = response.content\n    \n    guard_check = guardrail_tool.invoke(final_output)\n    if \"flagged\" in guard_check.lower():\n        # Optionally regenerate or sanitize response\n        return \"Sorry, I'm unable to provide that response. Let's talk about something safe.\"\n\n\n    return final_output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T15:30:18.764699Z","iopub.execute_input":"2025-04-04T15:30:18.764989Z","iopub.status.idle":"2025-04-04T15:30:18.886463Z","shell.execute_reply.started":"2025-04-04T15:30:18.764964Z","shell.execute_reply":"2025-04-04T15:30:18.885375Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"query = \"Tell me more about deep breathing?\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T15:30:18.887425Z","iopub.execute_input":"2025-04-04T15:30:18.887737Z","iopub.status.idle":"2025-04-04T15:30:18.891389Z","shell.execute_reply.started":"2025-04-04T15:30:18.887703Z","shell.execute_reply":"2025-04-04T15:30:18.890522Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"from langchain.memory import ChatMessageHistory","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T15:30:18.893318Z","iopub.execute_input":"2025-04-04T15:30:18.893520Z","iopub.status.idle":"2025-04-04T15:30:18.908218Z","shell.execute_reply.started":"2025-04-04T15:30:18.893502Z","shell.execute_reply":"2025-04-04T15:30:18.907406Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"from langchain.prompts import SystemMessagePromptTemplate\nfrom langchain.agents import initialize_agent\nfrom langchain.agents import AgentType\nimport uuid\nfrom langchain.memory import ChatMessageHistory\n\n# from langchain.memory.chat_message_histories import InMemoryChatMessageHistory\n\n\n\n\nstore = {}  # memory is maintained outside the chain\n\ndef get_session_history(session_id: str) -> ChatMessageHistory:\n    if session_id not in store:\n        store[session_id] = ChatMessageHistory()\n        print(store[session_id])\n    return store[session_id]\n    \n# # Format chat history list into plain string\n# def stringify_chat_history(messages: list) -> str:\n#     return \"\\n\".join([f\"{m.type}: {m.content}\" for m in messages]) if messages else \"\"\n\n# # Wrap llm_rephrase so it's runnable in LangGraph / LangChain\n# llm_rephrase_wrapped = RunnableLambda(lambda state: {\n#     \"output\": llm_rephrase.invoke(stringify_chat_history(state[\"chat_history\"]) + \"\\n\" + state[\"input\"])\n# })\n                                   \nchain = RunnableWithMessageHistory(\n    runnable=llm_rephrase,  # your rephrase LLM or chain\n    get_session_history=get_session_history,\n    input_messages_key=\"input\",\n    history_messages_key=\"chat_history\"\n)\n\n\n\n\ndef create_session_id():\n    return str(uuid.uuid4()) \nid = create_session_id()\n\n\nresponse = generate_rag_response(query,faiss_index, id,rephrase_tool, retriever_tool,chat_model)\nprint(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T15:30:18.909226Z","iopub.execute_input":"2025-04-04T15:30:18.909509Z","iopub.status.idle":"2025-04-04T15:30:42.375538Z","shell.execute_reply.started":"2025-04-04T15:30:18.909478Z","shell.execute_reply":"2025-04-04T15:30:42.374734Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n  warnings.warn(\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n\n[INST]\nYou are an empathetic therapy assistant. Given a conversation history and a follow-up user statement,\nyour task is to rewrite the statement as a **standalone query** to retrieve **relevant therapeutic advice** to give to user.\nChat History:\nNo previous messages.\n\nFollow Up Input: Tell me more about deep breathing?\n\nStandalone Question:\n[/INST]\n\"What's your favorite part of this session?\"\n (I'm not sure if you've heard it before.)\n \"How do I get my breath back into place when there's no oxygen in that chamber or whatnot.\" [IMG][/IMGS]\nThe first question was asked by one person who had been on Deep Breathing for over 10 years now…and they were all very happy with their experience! They said 'it feels good' but felt like nothing really happened at any\n\n[INST]\nYou are an empathetic therapy assistant. Given a conversation history and a follow-up user statement,\nyour task is to rewrite the statement as a **standalone query** to retrieve **relevant therapeutic advice** to give to user.\nChat History:\nNo previous messages.\n\nFollow Up Input: Tell me more about deep breathing?\n\nStandalone Question:\n[/INST]\n\"What's your favorite part of this session?\"\n (I'm not sure if you've heard it before.)\n \"How do I get my breath back into place when there's no oxygen in that chamber or whatnot.\" [IMG][/IMGS]\nThe first question was asked by one person who had been on Deep Breathing for over 10 years now…and they were all very happy with their experience! They said 'it feels good' but felt like nothing really happened at any\n[HumanMessage(content='5bc44330-85c1-4c90-b968-4dc2e145658f::Tell me more about deep breathing?', additional_kwargs={}, response_metadata={})]\ncontent=\"<s>[INST] \\n    ### Instruction:\\n    You are a supportive and empathetic therapy chatbot trained in evidence-based counseling techniques. \\n\\n    Guidelines:\\n    - You **do not diagnose** mental health conditions.\\n    - You **provide emotional support** and **suggest self-help strategies** based on cognitive behavioral therapy (CBT) and evidence-based practices retrieved from the context.\\n    - You **detect and address repetitive negative thought patterns** and **gently encourage professional counseling** when needed.\\n    - You **do not replace a licensed therapist** and will **always refer users to a professional** in cases of severe distress or crisis.\\n    - You **use non-judgmental, affirming language** that promotes self-compassion and self-awareness.\\n    \\n    Response Style:\\n    - Use **motivational interviewing techniques** (e.g., open-ended questions, reflections, affirmations).\\n    - Provide **psychoeducation** where relevant.\\n    - If the user expresses crisis-level distress (e.g., suicidal ideation, self-harm), provide **a crisis intervention message** and direct them to emergency help resources.\\n\\n    ### Context from Retrieved Documents:\\n    can be achieved through the implementation of enhanced training opportunities, AI -supported supervision, and \\nself-reflection. AI can be employed to simulate the role of the client in the development and practice of new \\nskills,  thereby assisting clinicians in enhancing their abilities by more accurately portraying a range of scenarios \\n(Luxton 2014). AI- based tools, such as Clinicalnotes.ai, have the potential to provide clinicians with supervision -\\naligned interventions by analys ing their notes and treatment progress. Moreover, these tools can assist \\nsupervisors in the planning of clinical practice.  \\nNatural language processing (NLP) is a subfield of artificial intelligence and linguistics that focuses on the \\ninteraction between computers and human language. Text analysis, a significant application of NLP, seeks to \\nderive meaningful insights from vast quantities of unstructured text data. The application of natural language\\n\\ndisorders (Sonmez and Hocaoglu 2024). As technology advances, it h as become feasible for Artificial intelligence \\n(AI) to fully emulate the capabilities of human imagination, emotions, intuition, and potential (Braga and Logan 2017). Furthermore, it is now feasible for AI to comprehend psychological processes, perceive an d respond to a \\nspectrum of human behaviours, including attention, motivation, emotion, creativity, planning and discussion (van den Bosch and Bronkhorst 2019, Dong et al. 2020).  \\nThe application of AI in therapy is not confined to the support of therapists and therapy chatbots. Such technology can assist therapists in the management of administrative tasks, thereby increasing efficiency and \\nallowing more time to be devoted to direct patient care. Moreover, chatbots and virtual assistants are being \\nAddress for Correspondence:  Fatih Bal, Sakarya University Faculty of Humanities and Social Sciences, Department of Psychology ,\\n\\nacross th e entire spectrum of care, from initial diagnosis to subsequent treatment (Thakkar et al. 2024). The \\nadvent of AI is inaugurating a new epoch in the domain of mental health care, revolutionizing the entire spectrum of activities, from the precision of diag nostic procedures to the implementation of therapeutic \\ninterventions (D'Alfonso 2020). AI offers cost -effective assistance in response to growing demand and, in some \\ncases, replaces human -led treatments.  The field of AI has witnessed considerable advancement over time, from \\nthe utilisation of chatbots in therapy sessions to the development of sophisticated data analysis tools. In recent years, with the continued evolution of this field, there have been notable advances in the application of AI in \\ntherapeuti c contexts. AI has become capable of analysing a range of data, including tools, speech patterns and\\n\\nincreasingly effective with continued use. Wysa is an online therapy application that employs an emotionally intelligent chatbot based on the cognitive behavioural therapy model. The app offers a variety of tools, including dialectical behaviour therap y, meditation, breathing exercises, yoga, and motivational videos. Additionally, the \\napp furnishes users with self -improvement tools, including medication reminders, wellness exercises, and deep \\nsleep training. The objective of the app is to address issues  such as mild depression and anxiety disorders. On \\noccasion, the vast quantity of queries can prove daunting for users. Sanvello is a chatbot based on CBT that places greater emphasis on cultivating mindfulness than on psychological relaxation. The app off ers a range of\\n    \\n\\n5bc44330-85c1-4c90-b968-4dc2e145658f::Tell me more about deep breathing?[/INST] Deep breathing is a relaxation technique that involves consciously inhaling and exhaling air in a slow and controlled manner. This technique can help reduce stress, lower heart rate, and promote a sense of calm. Here's a simple deep breathing exercise you can try:\\n\\n1. Find a quiet, comfortable place to sit or lie down.\\n2. Close your eyes and place one hand on your belly and the other on your chest.\\n3. Inhale slowly through your nose, allowing your belly to rise as you fill your lungs with air. Your hand on your belly should rise, while the hand on your chest should remain relatively still.\\n4. Hold the breath for a few seconds, then exhale slowly through your mouth.\\n5. Repeat this process for several minutes, focusing on your breath and letting go of any thoughts or worries.\\n\\nDeep breathing can be done anywhere, anytime, and can be a helpful tool for managing stress and anxiety throughout the day. If you find it difficult to remember to practice deep breathing, consider setting reminders on your phone or using an app that guides you through the exercise.\" additional_kwargs={} response_metadata={} id='run-6fc34c9a-5754-43b0-9d52-7d5805c46be0-0'\n<s>[INST] \n    ### Instruction:\n    You are a supportive and empathetic therapy chatbot trained in evidence-based counseling techniques. \n\n    Guidelines:\n    - You **do not diagnose** mental health conditions.\n    - You **provide emotional support** and **suggest self-help strategies** based on cognitive behavioral therapy (CBT) and evidence-based practices retrieved from the context.\n    - You **detect and address repetitive negative thought patterns** and **gently encourage professional counseling** when needed.\n    - You **do not replace a licensed therapist** and will **always refer users to a professional** in cases of severe distress or crisis.\n    - You **use non-judgmental, affirming language** that promotes self-compassion and self-awareness.\n    \n    Response Style:\n    - Use **motivational interviewing techniques** (e.g., open-ended questions, reflections, affirmations).\n    - Provide **psychoeducation** where relevant.\n    - If the user expresses crisis-level distress (e.g., suicidal ideation, self-harm), provide **a crisis intervention message** and direct them to emergency help resources.\n\n    ### Context from Retrieved Documents:\n    can be achieved through the implementation of enhanced training opportunities, AI -supported supervision, and \nself-reflection. AI can be employed to simulate the role of the client in the development and practice of new \nskills,  thereby assisting clinicians in enhancing their abilities by more accurately portraying a range of scenarios \n(Luxton 2014). AI- based tools, such as Clinicalnotes.ai, have the potential to provide clinicians with supervision -\naligned interventions by analys ing their notes and treatment progress. Moreover, these tools can assist \nsupervisors in the planning of clinical practice.  \nNatural language processing (NLP) is a subfield of artificial intelligence and linguistics that focuses on the \ninteraction between computers and human language. Text analysis, a significant application of NLP, seeks to \nderive meaningful insights from vast quantities of unstructured text data. The application of natural language\n\ndisorders (Sonmez and Hocaoglu 2024). As technology advances, it h as become feasible for Artificial intelligence \n(AI) to fully emulate the capabilities of human imagination, emotions, intuition, and potential (Braga and Logan 2017). Furthermore, it is now feasible for AI to comprehend psychological processes, perceive an d respond to a \nspectrum of human behaviours, including attention, motivation, emotion, creativity, planning and discussion (van den Bosch and Bronkhorst 2019, Dong et al. 2020).  \nThe application of AI in therapy is not confined to the support of therapists and therapy chatbots. Such technology can assist therapists in the management of administrative tasks, thereby increasing efficiency and \nallowing more time to be devoted to direct patient care. Moreover, chatbots and virtual assistants are being \nAddress for Correspondence:  Fatih Bal, Sakarya University Faculty of Humanities and Social Sciences, Department of Psychology ,\n\nacross th e entire spectrum of care, from initial diagnosis to subsequent treatment (Thakkar et al. 2024). The \nadvent of AI is inaugurating a new epoch in the domain of mental health care, revolutionizing the entire spectrum of activities, from the precision of diag nostic procedures to the implementation of therapeutic \ninterventions (D'Alfonso 2020). AI offers cost -effective assistance in response to growing demand and, in some \ncases, replaces human -led treatments.  The field of AI has witnessed considerable advancement over time, from \nthe utilisation of chatbots in therapy sessions to the development of sophisticated data analysis tools. In recent years, with the continued evolution of this field, there have been notable advances in the application of AI in \ntherapeuti c contexts. AI has become capable of analysing a range of data, including tools, speech patterns and\n\nincreasingly effective with continued use. Wysa is an online therapy application that employs an emotionally intelligent chatbot based on the cognitive behavioural therapy model. The app offers a variety of tools, including dialectical behaviour therap y, meditation, breathing exercises, yoga, and motivational videos. Additionally, the \napp furnishes users with self -improvement tools, including medication reminders, wellness exercises, and deep \nsleep training. The objective of the app is to address issues  such as mild depression and anxiety disorders. On \noccasion, the vast quantity of queries can prove daunting for users. Sanvello is a chatbot based on CBT that places greater emphasis on cultivating mindfulness than on psychological relaxation. The app off ers a range of\n    \n\n5bc44330-85c1-4c90-b968-4dc2e145658f::Tell me more about deep breathing?[/INST] Deep breathing is a relaxation technique that involves consciously inhaling and exhaling air in a slow and controlled manner. This technique can help reduce stress, lower heart rate, and promote a sense of calm. Here's a simple deep breathing exercise you can try:\n\n1. Find a quiet, comfortable place to sit or lie down.\n2. Close your eyes and place one hand on your belly and the other on your chest.\n3. Inhale slowly through your nose, allowing your belly to rise as you fill your lungs with air. Your hand on your belly should rise, while the hand on your chest should remain relatively still.\n4. Hold the breath for a few seconds, then exhale slowly through your mouth.\n5. Repeat this process for several minutes, focusing on your breath and letting go of any thoughts or worries.\n\nDeep breathing can be done anywhere, anytime, and can be a helpful tool for managing stress and anxiety throughout the day. If you find it difficult to remember to practice deep breathing, consider setting reminders on your phone or using an app that guides you through the exercise.\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"print(id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T15:30:42.376772Z","iopub.execute_input":"2025-04-04T15:30:42.377105Z","iopub.status.idle":"2025-04-04T15:30:42.381295Z","shell.execute_reply.started":"2025-04-04T15:30:42.377075Z","shell.execute_reply":"2025-04-04T15:30:42.380459Z"}},"outputs":[{"name":"stdout","text":"5bc44330-85c1-4c90-b968-4dc2e145658f\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"# query = \"What app are u referring to?\"\n# id = \"5bc44330-85c1-4c90-b968-4dc2e145658f\"\n# response = generate_rag_response(query,faiss_index, id,rephrase_tool, retriever_tool,chat_model)\n# print(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T15:32:14.811325Z","iopub.execute_input":"2025-04-04T15:32:14.811616Z","iopub.status.idle":"2025-04-04T15:32:14.815459Z","shell.execute_reply.started":"2025-04-04T15:32:14.811595Z","shell.execute_reply":"2025-04-04T15:32:14.814456Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}